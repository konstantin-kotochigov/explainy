#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã –¥–≤—É—Ö LLM –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö API –≤—ã–∑–æ–≤–æ–≤.
–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä notebook —Å –º–æ–∫-–¥–∞–Ω–Ω—ã–º–∏, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
"""

import sys
from pathlib import Path
import tempfile
import nbformat

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é
sys.path.insert(0, str(Path(__file__).parent.parent))

from main import save_explanation, enhance_notebook


def demonstrate_notebook_structure():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ notebook."""
    print("=" * 80)
    print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–¢–†–£–ö–¢–£–†–´ NOTEBOOK –° –î–í–£–ú–Ø LLM")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    with tempfile.TemporaryDirectory() as tmpdir:
        output_dir = Path(tmpdir)
        
        # –®–∞–≥ 1: Primary LLM (Gemini) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        print("\n[1/3] Primary LLM (Gemini) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ...")
        code = "demo_topic"
        explanation = """# DPR (2020)

**Dense Passage Retrieval** - —ç—Ç–æ –ø–æ–¥—Ö–æ–¥ –∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–º—É –ø–æ–∏—Å–∫—É, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ.

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

DPR –∏—Å–ø–æ–ª—å–∑—É–µ—Ç two-tower –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –¥–≤—É–º—è BERT —ç–Ω–∫–æ–¥–µ—Ä–∞–º–∏:
- **Query Encoder**: –∫–æ–¥–∏—Ä—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
- **Passage Encoder**: –∫–æ–¥–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã

## –ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã

1. –û–±—É—á–µ–Ω–∏–µ —ç–Ω–∫–æ–¥–µ—Ä–æ–≤ –Ω–∞ –ø–∞—Ä–∞—Ö (–∑–∞–ø—Ä–æ—Å, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç)
2. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ
3. –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ

## –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞

- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (–ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å–º—ã—Å–ª–∞, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)
- –í—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞
- –ë—ã—Å—Ç—Ä—ã–π –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –ø–æ—Å–ª–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"""
        
        filepath = save_explanation(output_dir, code, explanation)
        print(f"  ‚úì –°–æ–∑–¥–∞–Ω –±–∞–∑–æ–≤—ã–π notebook: {filepath.name}")
        
        # –®–∞–≥ 2: Secondary LLM (OpenAI) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏–∫—É
        print("\n[2/3] Secondary LLM (OpenAI) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑...")
        critique = """### –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã

1. ‚úÖ –ß–µ—Ç–∫–æ –æ–ø–∏—Å–∞–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ two-tower —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
2. ‚úÖ –ü—Ä–∏–≤–µ–¥–µ–Ω –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–∞–±–æ—Ç—ã –ø–æ —à–∞–≥–∞–º
3. ‚úÖ –£–∫–∞–∑–∞–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–æ–¥—Ö–æ–¥–∞

### –û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è

1. üìù –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, MS MARCO, Natural Questions)
2. üìù –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ (Recall@20, MRR)
3. üìù –£–ø–æ–º—è–Ω—É—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å BM25 –∏ –¥—Ä—É–≥–∏–º–∏ baseline –º–µ—Ç–æ–¥–∞–º–∏
4. üìù –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–µ –º–æ–¥–µ–ª–µ–π –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö –∫ —Ä–µ—Å—É—Ä—Å–∞–º

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ. –î–ª—è –ø–æ–ª–Ω–æ—Ç—ã –∫–∞—Ä—Ç–∏–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏."""
        
        print("  ‚úì –ö—Ä–∏—Ç–∏–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
        
        # –®–∞–≥ 3: Secondary LLM (OpenAI) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–¥-–ø—Ä–∏–º–µ—Ä
        print("\n[3/3] Secondary LLM (OpenAI) –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Python –∫–æ–¥-–ø—Ä–∏–º–µ—Ä...")
        code_example = """# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è DPR —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π Hugging Face

from transformers import DPRQuestionEncoder, DPRContextEncoder
from transformers import DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer
import torch
import numpy as np

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
question_encoder = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')
context_encoder = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')

question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')
context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')

# –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
query = "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞—è –∑–∞–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç—å?"

# –ë–∞–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
documents = [
    "–ö–≤–∞–Ω—Ç–æ–≤–∞—è –∑–∞–ø—É—Ç–∞–Ω–Ω–æ—Å—Ç—å - —ç—Ç–æ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ —è–≤–ª–µ–Ω–∏–µ, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º –∫–≤–∞–Ω—Ç–æ–≤—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–≤—É—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –≤–∑–∞–∏–º–æ–∑–∞–≤–∏—Å–∏–º—ã–º–∏",
    "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã—Ö —Å–∏—Å—Ç–µ–º",
    "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫—É–±–∏—Ç—ã –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"
]

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
query_input = question_tokenizer(query, return_tensors='pt')
query_embedding = question_encoder(**query_input).pooler_output

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
doc_embeddings = []
for doc in documents:
    doc_input = context_tokenizer(doc, return_tensors='pt', padding=True, truncation=True)
    doc_embedding = context_encoder(**doc_input).pooler_output
    doc_embeddings.append(doc_embedding)

doc_embeddings = torch.cat(doc_embeddings)

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ (dot product)
similarities = torch.matmul(query_embedding, doc_embeddings.T)

# –ü–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
top_doc_idx = torch.argmax(similarities).item()
print(f"–ù–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {documents[top_doc_idx]}")
print(f"Similarity score: {similarities[0][top_doc_idx]:.4f}")"""
        
        print("  ‚úì –ö–æ–¥-–ø—Ä–∏–º–µ—Ä —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∏—Ç–∏–∫—É –∏ –∫–æ–¥ –≤ notebook
        print("\n[4/4] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π –≤ notebook...")
        enhance_notebook(filepath, critique, code_example)
        print("  ‚úì Notebook —É–ª—É—á—à–µ–Ω")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ notebook
        print("\n" + "=" * 80)
        print("–°–¢–†–£–ö–¢–£–†–ê –§–ò–ù–ê–õ–¨–ù–û–ì–û NOTEBOOK")
        print("=" * 80)
        
        with open(filepath, 'r', encoding='utf-8') as f:
            nb = nbformat.read(f, as_version=4)
        
        print(f"\n–í—Å–µ–≥–æ —è—á–µ–µ–∫: {len(nb.cells)}")
        print("\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:")
        
        for i, cell in enumerate(nb.cells, 1):
            print(f"\n[–Ø—á–µ–π–∫–∞ {i}] –¢–∏–ø: {cell.cell_type.upper()}")
            
            if cell.cell_type == 'markdown':
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤
                preview = cell.source[:100].replace('\n', ' ')
                print(f"  –ü—Ä–µ–≤—å—é: {preview}...")
            else:
                # –î–ª—è –∫–æ–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                lines = cell.source.split('\n')
                print(f"  –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: {len(lines)}")
                print(f"  –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞: {lines[0] if lines else '–ø—É—Å—Ç–æ'}")
        
        print("\n" + "=" * 80)
        print("‚úì –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
        print("=" * 80)
        
        print("\n–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:")
        print("  1. Markdown: –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç Gemini")
        print("  2. Markdown: üìù –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –æ—Ç OpenAI")
        print("  3. Markdown: üíª –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–º–µ—Ä–∞ –∫–æ–¥–∞")
        print("  4. Code: Python –∫–æ–¥-–ø—Ä–∏–º–µ—Ä –æ—Ç OpenAI")
        
        return True


def main():
    """–ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏."""
    try:
        result = demonstrate_notebook_structure()
        return 0 if result else 1
    except Exception as e:
        print(f"\n‚úó –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
